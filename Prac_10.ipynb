{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 10**\n",
        "\n",
        "**Aim :   Advanced Topics in Information Retrieval**\n",
        "*   Implement a text summarization algorithm (e.g., extractive or abstractive).\n",
        "\n",
        "*   Build a question-answering system using techniques such as information\n",
        "extraction"
      ],
      "metadata": {
        "id": "FBxq1MDO7SnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "# Import required libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Download NLTK resources (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"\n",
        "Information Retrieval is the process of obtaining relevant information\n",
        "from a large collection of data. It plays an important role in search engines.\n",
        "Text summarization helps in reducing the size of documents while preserving\n",
        "important information. Automatic summarization is widely used in news\n",
        "applications and research domains.\n",
        "\"\"\"\n",
        "\n",
        "# Sentence tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Remove stop words and calculate word frequencies\n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_frequencies = {}\n",
        "\n",
        "for word in word_tokenize(text.lower()):\n",
        "    if word.isalnum() and word not in stop_words:\n",
        "        if word not in word_frequencies:\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "# Normalize word frequencies\n",
        "max_frequency = max(word_frequencies.values())\n",
        "for word in word_frequencies:\n",
        "    word_frequencies[word] /= max_frequency\n",
        "\n",
        "# Score sentences\n",
        "sentence_scores = {}\n",
        "for sentence in sentences:\n",
        "    for word in word_tokenize(sentence.lower()):\n",
        "        if word in word_frequencies:\n",
        "            if sentence not in sentence_scores:\n",
        "                sentence_scores[sentence] = word_frequencies[word]\n",
        "            else:\n",
        "                sentence_scores[sentence] += word_frequencies[word]\n",
        "\n",
        "# Select top 2 sentences\n",
        "summary_sentences = sorted(\n",
        "    sentence_scores,\n",
        "    key=sentence_scores.get,\n",
        "    reverse=True\n",
        ")[:2]\n",
        "\n",
        "# Generate summary\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enIHiiSWMWIL",
        "outputId": "e66ca535-c31f-4d58-8552-615485c69857"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " \n",
            "Information Retrieval is the process of obtaining relevant information\n",
            "from a large collection of data. Text summarization helps in reducing the size of documents while preserving\n",
            "important information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question–Answering System – Python Code"
      ],
      "metadata": {
        "id": "U56AxriyR9kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "# Import required libraries\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load spaCy language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input document\n",
        "text = \"\"\"\n",
        "Information Retrieval deals with the storage and retrieval of information.\n",
        "Search engines use IR techniques to retrieve relevant documents.\n",
        "Natural Language Processing helps computers understand human language.\n",
        "\"\"\"\n",
        "\n",
        "# Sentence tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Accept user question\n",
        "question = input(\"Enter your question: \")\n",
        "\n",
        "# Extract keywords from question\n",
        "question_doc = nlp(question)\n",
        "keywords = [\n",
        "    token.text.lower()\n",
        "    for token in question_doc\n",
        "    if not token.is_stop and not token.is_punct\n",
        "]\n",
        "\n",
        "# Find most relevant sentence\n",
        "best_sentence = \"\"\n",
        "max_score = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "    score = 0\n",
        "    sentence_doc = nlp(sentence.lower())\n",
        "\n",
        "    for token in sentence_doc:\n",
        "        if token.text in keywords:\n",
        "            score += 1\n",
        "\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "        best_sentence = sentence\n",
        "\n",
        "# Display answer\n",
        "if best_sentence:\n",
        "    print(\"Answer:\", best_sentence)\n",
        "else:\n",
        "    print(\"Answer not found in the document.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-SQu9vQR-Ez",
        "outputId": "1f6b8ae8-c82f-47d8-bd78-fe9cd0a62dd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Enter your question: What is information retrieval\n",
            "Answer: \n",
            "Information Retrieval deals with the storage and retrieval of information.\n"
          ]
        }
      ]
    }
  ]
}