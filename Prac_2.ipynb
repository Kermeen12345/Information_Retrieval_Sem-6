{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 2**\n",
        "\n",
        "**Aim : Retrieval Models**\n",
        "*   Implement the Boolean retrieval model and process queries.\n",
        "*   Implement the vector space model with TF-IDF weighting and cosine similarity.\n"
      ],
      "metadata": {
        "id": "FBxq1MDO7SnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Implement the Boolean retrieval model and process queries."
      ],
      "metadata": {
        "id": "JNnWTdzY1RnG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyJDo4l06yp0",
        "outputId": "c4a707f1-f756-463d-933b-2e0b7b7db13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Documents containing 'apple' AND 'banana': [1, 2]\n",
            "Documents containing 'apple' OR 'orange': [1, 2, 3]\n",
            "Documents NOT containing 'orange': [2, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "# Import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"apple banana orange\",\n",
        "    2: \"apple banana\",\n",
        "    3: \"banana orange\",\n",
        "    4: \"apple\"\n",
        "}\n",
        "\n",
        "# Build inverted index (stopwords removed)\n",
        "def build_index(docs):\n",
        "    index = {}\n",
        "    for doc_id, text in docs.items():\n",
        "        for term in text.lower().split():\n",
        "            if term not in stop:                         # remove stopwords\n",
        "                index.setdefault(term, set()).add(doc_id)\n",
        "    return index\n",
        "\n",
        "# Boolean operations\n",
        "def boolean_and(terms, index):\n",
        "    result = index.get(terms[0], set())\n",
        "    for t in terms[1:]: result &= index.get(t, set())\n",
        "    return list(result)\n",
        "\n",
        "def boolean_or(terms, index):\n",
        "    result = set()\n",
        "    for t in terms: result |= index.get(t, set())\n",
        "    return list(result)\n",
        "\n",
        "def boolean_not(term, index, total_docs):\n",
        "    return list(set(range(1, total_docs+1)) - index.get(term, set()))\n",
        "\n",
        "# Build index\n",
        "inv_index = build_index(docs)\n",
        "\n",
        "# Queries\n",
        "print(\"Documents containing 'apple' AND 'banana':\", boolean_and([\"apple\",\"banana\"], inv_index))\n",
        "print(\"Documents containing 'apple' OR 'orange':\", boolean_or([\"apple\",\"orange\"], inv_index))\n",
        "print(\"Documents NOT containing 'orange':\", boolean_not(\"orange\", inv_index, len(docs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Implement the vector space model with TF-IDF weighting and cosine\n",
        "similarity"
      ],
      "metadata": {
        "id": "d_mbYJph1qFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Documents\n",
        "train = [\"The sky is blue.\", \"The sun is bright.\"]\n",
        "test = [\"The sun in the sky is bright.\"]\n",
        "\n",
        "# Create TF-IDF pipeline\n",
        "vectorizer = CountVectorizer(stop_words=stop)\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# Bag-of-Words vectors\n",
        "train_bow = vectorizer.fit_transform(train).toarray()\n",
        "test_bow = vectorizer.transform(test).toarray()\n",
        "\n",
        "print(\"Train BoW:\", train_bow)\n",
        "print(\"Test BoW:\", test_bow)\n",
        "\n",
        "# Cosine similarity\n",
        "cos = lambda a, b: round(np.inner(a, b) / (norm(a)*norm(b)), 3)\n",
        "\n",
        "# Show vectors\n",
        "for vec in train_bow: print(vec)\n",
        "for tvec in test_bow:\n",
        "    print(tvec)\n",
        "    print(cos(vec, tvec))\n",
        "\n",
        "# TF-IDF values\n",
        "print(\"\\nTrain TF-IDF:\")\n",
        "print(transformer.fit_transform(train_bow).toarray())\n",
        "\n",
        "print(\"\\nTest TF-IDF:\")\n",
        "print(transformer.fit_transform(test_bow).todense())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzvkVma01rqG",
        "outputId": "00aee3eb-e79d-4c34-a3a0-fb80e3942e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Train BoW: [[1 0 1 0]\n",
            " [0 1 0 1]]\n",
            "Test BoW: [[0 1 1 1]]\n",
            "[1 0 1 0]\n",
            "[0 1 0 1]\n",
            "[0 1 1 1]\n",
            "0.816\n",
            "\n",
            "Train TF-IDF:\n",
            "[[0.70710678 0.         0.70710678 0.        ]\n",
            " [0.         0.70710678 0.         0.70710678]]\n",
            "\n",
            "Test TF-IDF:\n",
            "[[0.         0.57735027 0.57735027 0.57735027]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus.\n",
        "\n",
        "Document 1: 'this is the first document.'\n",
        "\n",
        "Document 2: 'this document is the second document.'\n",
        "\n",
        "Document 3: 'And this is the third one.'\n",
        "\n",
        "Document 4: 'Is this the first document?'\n",
        "\n",
        "Process the query “first and third”."
      ],
      "metadata": {
        "id": "ZaJSwzg48dgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"this is the first document\",\n",
        "    2: \"this document is the second document\",\n",
        "    3: \"and this is the third one\",\n",
        "    4: \"is this the first document\"\n",
        "}\n",
        "\n",
        "# Build inverted index\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for term in text.split():\n",
        "        index.setdefault(term, set()).add(doc_id)\n",
        "\n",
        "# Boolean AND\n",
        "def boolean_and(terms):\n",
        "    sets = [index.get(t, set()) for t in terms]\n",
        "    return list(set.intersection(*sets)) if sets else []\n",
        "\n",
        "# Query\n",
        "result = boolean_and([\"first\", \"third\"])\n",
        "\n",
        "print(\"Documents matching 'first AND third':\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAHHN8Ms8m23",
        "outputId": "6bd74c4b-4bbe-4732-ab63-b806e67527f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Documents matching 'first AND third': []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus.\n",
        "\n",
        "Document 1:The cat chased the dog around the garden.\n",
        "\n",
        "Document2: She was sitting in the garden last night.\n",
        "\n",
        "Document 3: I read the book the night before.\n",
        "\n",
        "Process the query “garden or night”."
      ],
      "metadata": {
        "id": "GaGr1UtJ8nNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"The cat chased the dog around the garden\",\n",
        "    2: \"She was sitting in the garden last night\",\n",
        "    3: \"I read the book the night before\"\n",
        "}\n",
        "\n",
        "# Build inverted index\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for word in text.lower().split():\n",
        "        index.setdefault(word, set()).add(doc_id)\n",
        "\n",
        "# Boolean OR\n",
        "def boolean_or(terms):\n",
        "    return list(set().union(*(index.get(t, set()) for t in terms)))\n",
        "\n",
        "# Query\n",
        "result = boolean_or([\"garden\", \"night\"])\n",
        "\n",
        "print(\"Documents matching 'garden OR night':\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6-lyFqY8tQX",
        "outputId": "e296a784-09eb-41ea-f694-67c3236ba249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Documents matching 'garden OR night': [1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus\n",
        "\n",
        "Document 1:BSc lectures start at 7.\n",
        "\n",
        "Document 2:My lectures are over.\n",
        "\n",
        "Document 3: Today is a holiday.\n",
        "\n",
        "Process the query “not lectures”"
      ],
      "metadata": {
        "id": "SQ4rTs--8tfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"BSc lectures start at 7\",\n",
        "    2: \"My lectures are over\",\n",
        "    3: \"Today is a holiday\"\n",
        "}\n",
        "\n",
        "# Build inverted index without stopwords\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for word in text.lower().split():\n",
        "        if word not in stop:\n",
        "            index.setdefault(word, set()).add(doc_id)\n",
        "\n",
        "# Boolean NOT\n",
        "def boolean_not(term):\n",
        "    return list(set(docs.keys()) - index.get(term, set()))\n",
        "\n",
        "# Query\n",
        "result = boolean_not(\"lectures\")\n",
        "\n",
        "print(\"Documents matching 'NOT lectures':\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30HJXPYT8yaX",
        "outputId": "3b646ff9-c4e9-4b8e-cd89-3e2a655d42ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Documents matching 'NOT lectures': [3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "\n",
        "Implement the vector space model with TF-IDF weighting for the\n",
        "following corpus\n",
        "\n",
        "Document 1: \"Document about python programming language and data\n",
        "analysis.\"\n",
        "\n",
        "Document 2: \"Document discussing machine learning algorithms and\n",
        "programming techniques.\"\n",
        "\n",
        "Document3: \"Overview of natural language processing and its\n",
        "applications.\"\n",
        "\n",
        "query = \"python programming\""
      ],
      "metadata": {
        "id": "BxN7FUkE80VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# Documents\n",
        "docs = [\n",
        "    \"Document about python programming language and data analysis.\",\n",
        "    \"Document discussing machine learning algorithms and programming techniques.\",\n",
        "    \"Overview of natural language processing and its applications.\"\n",
        "]\n",
        "\n",
        "query = [\"python programming\"]\n",
        "\n",
        "# Bag-of-Words with Auto Stopword Removal\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# TF-IDF for documents\n",
        "doc_tfidf = transformer.fit_transform(vectorizer.fit_transform(docs)).toarray()\n",
        "\n",
        "# TF-IDF for query\n",
        "query_tfidf = transformer.transform(vectorizer.transform(query)).toarray()\n",
        "\n",
        "# Cosine similarity\n",
        "cos = lambda a, b: round(np.inner(a, b) / (norm(a) * norm(b)), 3)\n",
        "\n",
        "# Output\n",
        "print(\"TF-IDF for documents:\")\n",
        "print(doc_tfidf)\n",
        "\n",
        "print(\"\\nTF-IDF for query:\")\n",
        "print(query_tfidf)\n",
        "\n",
        "print(\"\\nCosine Similarity Scores:\")\n",
        "for i, vec in enumerate(doc_tfidf, 1):\n",
        "    print(f\"Document {i}: {cos(vec, query_tfidf[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wHel9MV88kf",
        "outputId": "995090de-d9e8-46d7-893e-6f08f7223c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "TF-IDF for documents:\n",
            "[[0.         0.45954803 0.         0.45954803 0.         0.34949812\n",
            "  0.34949812 0.         0.         0.         0.         0.\n",
            "  0.34949812 0.45954803 0.        ]\n",
            " [0.40301621 0.         0.         0.         0.40301621 0.30650422\n",
            "  0.         0.40301621 0.40301621 0.         0.         0.\n",
            "  0.30650422 0.         0.40301621]\n",
            " [0.         0.         0.46735098 0.         0.         0.\n",
            "  0.35543247 0.         0.         0.46735098 0.46735098 0.46735098\n",
            "  0.         0.         0.        ]]\n",
            "\n",
            "TF-IDF for query:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.60534851 0.79596054 0.        ]]\n",
            "\n",
            "Cosine Similarity Scores:\n",
            "Document 1: 0.577\n",
            "Document 2: 0.186\n",
            "Document 3: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus\n",
        "\n",
        "Document 1:The university exam is scheduled next week.\n",
        "\n",
        "Document2: The university of mumbai has declared the result.\n",
        "\n",
        "Process the query “university and Mumbai”."
      ],
      "metadata": {
        "id": "aiXUXSqnBPjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T074 Kermeen\")\n",
        "\n",
        "# Stopwords list (short manual list for simplicity)\n",
        "stopwords = {\"the\", \"is\", \"has\", \"a\", \"of\", \"in\", \"at\", \"on\"}\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"The university exam is scheduled next week\",\n",
        "    2: \"The university of mumbai has declared the result\"\n",
        "}\n",
        "\n",
        "# Build inverted index (remove stopwords)\n",
        "def build_index(docs):\n",
        "    index = {}\n",
        "    for doc_id, text in docs.items():\n",
        "        for term in text.lower().split():\n",
        "            if term not in stopwords:        # remove stopwords\n",
        "                index.setdefault(term, set()).add(doc_id)\n",
        "    return index\n",
        "\n",
        "# Boolean AND operation\n",
        "def boolean_and(terms, index):\n",
        "    result = index.get(terms[0], set())\n",
        "    for term in terms[1:]:\n",
        "        result &= index.get(term, set())\n",
        "    return list(result)\n",
        "\n",
        "# Build index\n",
        "inverted_index = build_index(docs)\n",
        "\n",
        "# Query: remove stopwords automatically\n",
        "query = [t for t in [\"university\", \"mumbai\"] if t not in stopwords]\n",
        "\n",
        "# Process query\n",
        "result = boolean_and(query, inverted_index)\n",
        "\n",
        "print(\"Documents matching 'university AND mumbai':\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56847d5-2f8d-4cc5-9a09-1ea269694345",
        "id": "0LTSsjDPBXiB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T074 Kermeen\n",
            "Documents matching 'university AND mumbai': [2]\n"
          ]
        }
      ]
    }
  ]
}